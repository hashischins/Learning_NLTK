#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug  2 15:05:59 2017

@author: hashischins
"""

import nltk
nltk.download('all')
from nltk.text import Text

nltk.download('tokenizers/punkt/PY3/english.pickle')


fieldids = nltk.corpus.gutenberg.fileids()  
print(fieldids) 

hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')
len(hamlet)


#You cannot carry out concordancing (and other tasks from Section 1.1) using a text defined
#this way. Instead you have to make the following statement:
hamlet = nltk.Text(nltk.corpus.gutenberg.words('shakespeare-hamlet.txt'))

#test Cases
hamlet.concordance('anger')
hamlet.concordance('sorrow')

#Alternative way of doing the same thing
from nltk.corpus import gutenberg
gutenberg.fileids()

#A short program to display other information about the text

for fileid in gutenberg.fileids():
    num_chars = len(gutenberg.raw(fileid))
    num_words = len(gutenberg.words(fileid))
    num_sents = len(gutenberg.sents(fileid))
    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))
    print (int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab), fileid)
    
""" 3 different parameters have emerged from this program
    1) Average Word Length
    2) Average Sentence Length
    3) Number of times each vocabulary item appears in the text on average (Or you could call it Lexical Diversity Score)
    
#Tokenizing
from nltk import word_tokenize,sent_tokenize


